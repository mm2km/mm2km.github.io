<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Expanding Visual Spatial Reasoning from mm to km.">
  <meta name="keywords" content="SpaceVista">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SpaceVista</title>

  <!-- Fonts (with swap to avoid FOIT) -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@700&display=swap" rel="stylesheet">
  
  <!-- Core CSS (keep minimal, remove duplicates) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="icon" href="./static/images/logo_v2.svg">
  <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@700&display=swap" rel="stylesheet">

  <!-- Additional CSS for custom styling -->
  <style>
   .spacevista-title {
      font-family: 'Merriweather', 'Times New Roman', serif;
      font-weight: 600; 
      font-size: 1.2em;
      display: inline-flex;
      align-items: center;
      margin-left: 1px;
    }
      
    .logo-svg {
        height: 72px;  
        width: auto;  
        margin-right: 5px;  
        vertical-align: middle; 
    }
          
    .normal-title {
      font-size: 0.7em !important;
      white-space: nowrap;
    }
    
    .unit-mmkm {
      font-weight: bold;
      font-family: 'Courier New', monospace;
      font-size: 1.1em;
    }
    
    .email-symbol {
      position: absolute;
      top: -5px;
      right: -30px;
      font-size: 14px;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img src="./static/images/logo_v2.png" alt="Logo" class="logo-svg">
            <span class="spacevista-title">SpaceVista</span><br>
            <span class="normal-title">All-Scale Visual Spatial Reasoning from <span class="unit-mmkm">mm</span> to <span class="unit-mmkm">km</span>
            </span>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Peiwen Sun</a>
              <sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Shiqiang Lang</a>
              <sup>3</sup>,
            </span>
            <span class="author-block">
              <a>Dongming Wu</a>
              <sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Yi Ding</a>
              <sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Kaituo Feng</a>
              <sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Huadai Liu</a>
              <sup>4</sup>,
            </span>
            <span class="author-block">
              <a>Zhen Ye</a>
              <sup>4</sup>,
            </span>
            <span class="author-block">
              <a>Rui Liu</a>
              <sup>1</sup>,
            </span><br>
            <span class="author-block">
              <a>Yun-Hui Liu</a>
              <sup>1</sup>,
            </span>
            <span class="author-block">
              <a>Jianan Wang</a>
              <sup>2</sup>,
            </span>
            <span class="author-block">
              <a>Xiangyu Yue</a>
              <sup>1,</sup>
              <i class="fas fa-envelope email-symbol" style="position: relative; top: -8px; left: 1px;"></i>
            </span>
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Multimedia Lab, Chinese University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>Astribot,</span><br>
            <span class="author-block"><sup>3</sup>Beijing University of Posts and Telecommunications,</span><br>
            <span class="author-block"><sup>4</sup>Hong Kong University of Science and Technology</span>
          </div>

          <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-images"></i>
                    </span>
                    <span>Data</span>
                    </a>
              </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <img src="./static/images/teaser.jpg" alt="" style="display:block;width:100%;height:auto;margin-bottom:24px;" loading="eager" fetchpriority="high" decoding="async" />
        <div class="content has-text-justified">
        With the current surge in spatial reasoning explorations, researchers have 
        made significant progress in understanding indoor scenes, but still struggle with diverse applications such as robotics and autonomous driving. 
        This paper aims to advance all-scale spatial reasoning across diverse scenarios by tackling two key challenges:
        1) the heavy reliance on indoor 3D scans and labor-intensive manual annotations for dataset curation; 
        2) the absence of effective all-scale scene modeling, which often leads to overfitting to individual scenes.
        In this paper, we introduce a holistic solution that integrates a structured spatial reasoning knowledge system, scale-aware modeling, 
        and a progressive training paradigm, as the <strong>first attempt</strong> to broaden the all-scale spatial intelligence of MLLMs to the best of our knowledge.
        Using a task-specific, specialist-driven automated pipeline, we curate over 38K video scenes across 5 spatial scales to create <strong>SpaceVista-1M</strong>, 
        a dataset comprising approximately 1M spatial QA pairs spanning 19 diverse task types. While specialist models can inject useful domain knowledge, 
        they are not reliable for evaluation. We then build an all-scale benchmark with precise annotations by manually recording, retrieving, and assembling 
        video-based data. However, naive training with SpaceVista-1M often yields suboptimal results due to the potential knowledge conflict. Accordingly, we 
        introduce <strong>SpaceVista-7B</strong>, a spatial reasoning model that accepts dense inputs beyond semantics and uses scale as an anchor for scale-aware experts 
        and progressive rewards. Finally, extensive evaluations across 5 benchmarks, including our <strong>SpaceVista-Bench</strong>, demonstrate competitive 
        performance, showcasing strong generalization across all scales and scenarios.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">What is SpaceVista?</h2>
        <div class="content has-text-justified">
          <figure class="image">
          <img src="./static/images/intro_teaser_v3.jpg" alt="data_graph" style="width:700px; height:700px; object-fit:contain; display:block; margin:0 auto;" loading="lazy" decoding="async">
          </figure>
          Spatial reasoning, the ability to sense, interpret, and interact with environments across scales from tiny objects understanding to remote drone sensing, 
          is crucial for next-generation intelligent systems. <strong>All-scale reasoning</strong> capability supports diverse applications: $mm$ for advanced manufacturing~\citep{robospatial}, $cm$ and $m$ for embodied 
          intelligence~\citep{pan2025omnimanip}, $10m$ for autonomous driving~\citep{autodrive}, and $100m$ for drone-based sensing~\citep{uavsurvey}.
          
          From the data perspective, pioneer works SpaceR,Spar-7M,InternSpatial
          utilize more scanning-based data, or image-based data employing fully automated pipelines to acquire additional information for SFT and RL. 
          Concurrently, a series of outstanding works SpaceR,Spar-7M have improved the performance of existing models by refining the training and thinking approaches. 
          
          Despite prior works' advancements, their spatial perception capabilities are primarily limited to indoor settings, specific objects, and constrained scales. 
          Moreover, current methodologies lack dedicated training frameworks for holistic all-scale scene understanding. To bridge this gap, we introduce the 
          <strong>first comprehensive solution</strong> to address data, model, and evaluation dimensions for all-scale scenarios. 

          Previous datasets \citep{yang2025thinking,mmsibench,spacer,spar12m} for spatial reasoning have primarily been constructed based on indoor scanning video data.
        </div>
      </div>
    </div>
  </div>
</section>
  

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">From <span class="unit-mmkm">mm</span> to <span class="unit-mmkm">km</span> Dataset: SpaceVista-1M</h2>
        <div class="content has-text-justified">
          We introduce <strong>SpaceVista-Benchmark</strong>, a large-scale multi-scope spatial reasoning benchmark that extends beyond the limitations of existing datasets, 
          which are typically constrained by high annotation and scanning costs. Building on over <strong>40K curated scenes</strong> across five spatial scales, 
          we construct <strong>SpaceVista-1M</strong>, comprising approximately <strong>1M spatial QA pairs</strong> spanning <strong>19 task types</strong>. </p>
          To further enrich spatial diversity, SpaceVista encompasses <strong>15 tasks</strong> across <strong>5 scene categories</strong> and more than <strong>25 
          subscene types</strong>, supported by expert-driven automated annotation to ensure balanced coverage across scales and contexts.
        </div>
        <figure class="image">
          <img src="./static/images/data_graph_v2.jpg" alt="data_graph" style="width:700px; height:700px; object-fit:contain; display:block; margin:0 auto;" loading="lazy" decoding="async">
        </figure>
      </div>
    </div>
  </div>
</section>  

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Model: SpaceVista-7B</h2>
        <div class="content has-text-justified">
          <figure class="image" style="margin-bottom:24px;">
            <img src="./static/images/pipeline_v4.jpg" alt="pipeline" loading="lazy" decoding="async">
          </figure>
          SpaceVista-7B ingests a question with images and videos and 3D geometry, encodes them, projects features to a shared space, and fuses them in an 
          LLM through learnable interaction. A LoRA style scale expert with a scale aware router adapts the model to different spatial scales. 
          Training uses reinforcement learning with stepwise rewards, including scale estimation, semantic recognition, result correctness, and format correctness, 
          to align reasoning and final answers.
        </div>
      </div>
    </div>
  </div>
</section> 



  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment</h2>
        <style>
          .img-pair {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            gap: 0;
          }
          .img-pair img { display: block; }
        </style>

        <div class="img-pair">
          <img src="./static/images/radar.png" alt="experiment-2"
               style="width:460px; height:460px; object-fit:contain;margin-bottom:24px;" loading="lazy" decoding="async">
        </div>
      
        <div class="content has-text-justified">
          <p>
            <strong>Results overview.</strong> The left figure, together with the overall results, summarizes performance across four scenarios: Tiny Tabletop, Tabletop, Indoor, and Outdoor. 
            We further evaluate closed-source, open-source, and customized spatial reasoning models, showing consistent improvements across different scales and environments.
          </p>
          <p>
            <strong>Evaluation suite.</strong> The right figure presents evaluation results of Qwen2.5-VL-7B, SpatialR, SpatialMLLM, VILASR, and our SpaceVista 
            on VSI Bench, STI Bench, SIRIBench, MMSI Bench, SPAR Bench, and four internal evaluation sets, highlighting the robustness and competitiveness of our model.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  /* 统一宽度容器 */
  .scene-container {
    width: 960px;
    margin: 0 auto;
  }

  /* 按钮区 */
  .scene-switcher {
    display: flex;
    width: 100%;
    border-radius: 10px 10px 0 0;
    overflow: visible;
    background: #f0f0f0;
  }

  .scene-switcher .button {
    position: relative;
    flex: 1;
    font-weight: 600;
    border-radius: 0;
    border: none;
    box-shadow: none;
    margin: 0;
    padding: 12px 0;
    font-size: 15px;
    color: #555;
    background: #f0f0f0;
    transition: all 0.25s ease;
    cursor: pointer;
  }

  .scene-switcher .button:hover { background: #e0e0e0; color: #000; }
  .scene-switcher .button.is-active { background: #363636; color: #fff; font-weight: 700; }

  /* 展示区 */
  .scene-frame {
    width: 960px;
    height: 680px;
    border: 1.5px solid #bbb;
    border-top: none;
    border-radius: 0 0 10px 10px;
    background: #fafafa;
    display: flex;
    align-items: center;
    justify-content: center;
    overflow: hidden;
  }
  .scene-frame img {
    width: 100%;
    height: 100%;
    object-fit: contain;
  }

  .scene-switcher .button:not(.is-active)::after {
    content: "Click to switch scenes";
    position: absolute;
    left: 50%;
    top: calc(100% + 10px);
    transform: translateX(-50%) translateY(4px);
    background: #363636;
    color: #fff;
    font-size: 12px;
    line-height: 1;
    padding: 6px 8px;
    border-radius: 6px;
    white-space: nowrap;
    pointer-events: none;
    opacity: 0;
    transition: opacity .18s ease, transform .18s ease;
    z-index: 2;
  }
  .scene-switcher .button:not(.is-active)::before {
    content: "";
    position: absolute;
    left: 50%;
    top: 100%;
    transform: translateX(-50%);
    border: 6px solid transparent;
    border-top-color: #363636;
    opacity: 0;
    transition: opacity .18s ease;
    z-index: 2;
  }
  .scene-switcher .button:not(.is-active):hover::after,
  .scene-switcher .button:not(.is-active):hover::before {
    opacity: 1;
    transform: translateX(-50%) translateY(0);
  }
  .scene-row .scene-gallery .scene-switcher .button {
    font-size: 13px;   /* 改成你需要的值，如 12/14/16px */
    line-height: 1.2;  /* 可选：让文字更紧凑 */
    /* 可选：调节内边距，避免按钮变得过高或过矮 */
    padding-top: 10px;
    padding-bottom: 10px;
  }
  /* === 新增：左右并排布局（不改变其它样式的行为） === */
  .scene-row {
    width: 1200px;              /* 如需全宽可改为 100% */
    max-width: 100%;
    margin: 0 auto;
    display: flex;
    gap: 24px;                  /* 两个容器之间的间距 */
    align-items: flex-start;
    justify-content: center;
  }
  /* 仅当作为 .scene-row 子元素时覆盖固定宽度与外边距 */
  .scene-row .scene-container {
    margin: 0;                  /* 覆盖原本的居中外边距 */
    flex: 1 1 0;                /* 等分宽度 */
    width: auto;                /* 覆盖原来的 width:960px */
  }
  .scene-row .scene-switcher { width: 100%; }
  .scene-row .scene-frame {
    width: 100%;                /* 覆盖原来的 width:960px */
    height: 420px;              /* 调整为更适合并排显示的高度 */
  }
  
  @media (max-width: 1100px) {
    .scene-row { flex-direction: column; }
    .scene-row .scene-frame { height: 480px; }
  }
  .scene-row .scene-gallery .title.is-3{
      font-size: 24px;  
      line-height: 1.25;
  }
  
</style>

<section class="section">
  <div class="is-centered has-text-centered">

    <!-- 一行容器，左右并排放置两个组件 -->
    <div class="scene-row">

      <!-- ===== 组件实例 A ===== -->
      <div class="scene-container scene-gallery">
        <div class="title is-3">Scenes Data Preview</div>

        <div class="scene-switcher">
          <button type="button" class="button" data-src="./static/images/D6_uco_3d_data.jpg">Tiny Tabletop</button>
          <button type="button" class="button" data-src="./static/images/D5_wildrgbd_data.jpg">Tabletop</button>
          <button type="button" class="button" data-src="./static/images/D7_our_collected.jpg">Self-Collected</button>
          <button type="button" class="button is-active" data-src="./static/images/D1_vsi_data.jpg">Indoor</button>
          <button type="button" class="button" data-src="./static/images/D2_DL3DV_indoor_data.jpg">Wild Indoor</button>
          <button type="button" class="button" data-src="./static/images/D3_DL3DV_outdoor_data.jpg">Outdoor</button>
          <button type="button" class="button" data-src="./static/images/D4_DL3DV_drone_data.jpg">Drone</button>
        </div>

        <div class="scene-frame">
          <img data-role="scene" src="" alt="Scene A" loading="eager" fetchpriority="high" decoding="async">
        </div>
      </div>

      <!-- ===== 组件实例 B ===== -->
      <div class="scene-container scene-gallery">
        <div class="title is-3">Word Cloud</div>

        <div class="scene-switcher">
          <button type="button" class="button is-active" data-src="./static/images/tinytabletop_data.jpg">Tiny Tabletop</button>
          <button type="button" class="button" data-src="./static/images/indoor_data.jpg">Tabletop</button>
          <button type="button" class="button" data-src="./static/images/ourcollected_data.jpg">Self-Collected</button>
          <button type="button" class="button" data-src="./static/images/previous_indoor_data.jpg">Previous Indoor</button>
          <button type="button" class="button" data-src="./static/images/indoor_data.jpg">Indoor</button>
          <button type="button" class="button" data-src="./static/images/outdoor_data.jpg">Outdoor</button>
        </div>

        <div class="scene-frame">
          <img data-role="scene" src="" alt="Scene B" loading="eager" decoding="async">
        </div>
      </div>

    </div><!-- /scene-row -->

  </div>
</section>

<script>
document.addEventListener('DOMContentLoaded', () => {
  // 针对页面上所有 .scene-gallery 实例分别初始化
  document.querySelectorAll('.scene-gallery').forEach(gallery => {
    const switcher = gallery.querySelector('.scene-switcher');
    const img = gallery.querySelector('.scene-frame img[data-role="scene"]');
    if (!switcher || !img) return;

    // 首次根据 .is-active 同步默认图片
    const active = switcher.querySelector('.button.is-active') || switcher.querySelector('.button');
    if (active && active.dataset.src) {
      img.src = active.dataset.src;
      img.alt = active.textContent.trim();
    }

    // 事件委托：只影响当前 gallery
    switcher.addEventListener('click', (e) => {
      const btn = e.target.closest('.button');
      if (!btn || !switcher.contains(btn)) return;

      switcher.querySelectorAll('.button.is-active').forEach(b => b.classList.remove('is-active'));
      btn.classList.add('is-active');

      if (btn.dataset.src) {
        img.src = btn.dataset.src;
        img.alt = btn.textContent.trim();
      }
    });
  });
});
</script>

<div class="wrap">
</tbody>
</table>
<div class="legend">
</div>
</div>
</div>


<script>
(function() {
const table = document.getElementById('leaderboard');
const thead = table.tHead;
const tbody = table.tBodies[0];


// 清理其他表头的状态
function resetHeaders(activeTh) {
[...thead.querySelectorAll('th.sortable')].forEach(th => {
if (th !== activeTh) th.setAttribute('aria-sort', 'none');
});
}


function parseByType(value, type) {
if (type === 'number') {
const n = parseFloat(String(value).replace(/[^\d.\-]/g, ''));
return Number.isNaN(n) ? NaN : n;
}
if (type === 'date') {
// 支持 YYYY-MM-DD
const t = Date.parse(value);
return Number.isNaN(t) ? NaN : t;
}
return String(value).toLowerCase();
}


function compare(a, b, type, dir) {
const isAsc = dir === 'ascending';
let va = parseByType(a, type);
let vb = parseByType(b, type);


if (type === 'text') {
const res = va.localeCompare(vb, 'zh-Hans');
return isAsc ? res : -res;
}


// number / date: 把 NaN 放到末尾
const aNaN = Number.isNaN(va);
const bNaN = Number.isNaN(vb);
if (aNaN && bNaN) return 0;
if (aNaN) return 1;
if (bNaN) return -1;
const res = va - vb;
return isAsc ? res : -res;
}


function sortBy(th) {
const colIndex = [...th.parentNode.children].indexOf(th);
const type = th.dataset.type || 'text';
const current = th.getAttribute('aria-sort');
const nextDir = current === 'ascending' ? 'descending' : 'ascending';
th.setAttribute('aria-sort', nextDir);
resetHeaders(th);


const rows = [...tbody.querySelectorAll('tr')];
rows.sort((rowA, rowB) => {
const cellA = rowA.children[colIndex];
const cellB = rowB.children[colIndex];
const aVal = cellA.dataset.sort ?? cellA.textContent.trim();
const bVal = cellB.dataset.sort ?? cellB.textContent.trim();
return compare(aVal, bVal, type, nextDir);
});
rows.forEach(r => tbody.appendChild(r));
}


thead.addEventListener('click', (e) => {
const th = e.target.closest('th.sortable');
if (!th) return;
sortBy(th);
});


// 默认按排名升序
const defaultTh = thead.querySelector('th.sortable');
if (defaultTh) {
defaultTh.setAttribute('aria-sort', 'ascending');
sortBy(defaultTh); // 触发一次，让箭头状态到位
}
})();
</script>


  

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> 
            of <a href="https://nerfies.github.io/">Nerfies website</a>, 
            we just ask that you link back to Nerfies page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
