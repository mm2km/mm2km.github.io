<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="All-Scale Visual Spatial Reasoning from mm to km.">
  <meta name="keywords" content="SpaceVista">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SpaceVista: All-Scale Visual Spatial Reasoning from mm to km</title>

  <!-- Fonts (with swap to avoid FOIT) -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@700&display=swap" rel="stylesheet">
  
  <!-- Core CSS (keep minimal, remove duplicates) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="icon" href="./static/images/logo_v2.svg">
  <link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@700;800&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Source+Code+Pro:wght@400;700&family=IBM+Plex+Mono:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@700&display=swap" rel="stylesheet">
  <!-- Additional CSS for custom styling -->
  <style>
    .fancy-line {
      width: 1000px;          /* æ¨ªçº¿æ€»é•¿åº¦ï¼ŒçŸ­ä¸€äº› */
      height: 1px;           /* æ¨ªçº¿é«˜åº¦ï¼Œæ›´ç»† */
      background: linear-gradient(to right, 
                                  transparent,   /* å·¦ç«¯æ¸ç»† */
                                  #1a202c 50%,   /* ä¸­é—´é¢œè‰²æœ€ç²— */
                                  transparent);  /* å³ç«¯æ¸ç»† */
      margin: 20px auto;     /* ä¸Šä¸‹é—´è· + å±…ä¸­ */
      border-radius: 1px;    /* åœ†è§’ï¼Œä½¿è¿‡æ¸¡æŸ”å’Œ */
    }
    .avqa-title {
      font-family: 'Montserrat', 'Arial', sans-serif;
      font-weight: 900;       /* å¤§æ ‡é¢˜å¯ç”¨æ›´ç²— */
      font-size: 2.0rem;
      letter-spacing: -0.5px;
      color: #222222;
      margin-bottom: 18px;
      display: inline-flex;       /* å›¾ç‰‡å’Œæ–‡å­—åœ¨åŒä¸€è¡Œ */
      align-items: center;        /* å‚ç›´å±…ä¸­ */
      justify-content: center;    /* ä¿æŒæ•´ä½“å±…ä¸­ */
      gap: 10px;                  /* å›¾ç‰‡å’Œæ–‡å­—ä¹‹é—´çš„é—´è· */
      text-align: center;          /* æ–‡æœ¬å±…ä¸­ï¼ˆå¯é€‰ï¼‰ */
    }
    .avqa-title2 {
           font-family: 'Montserrat', 'Arial', sans-serif;
      font-weight: 900;       /* å¤§æ ‡é¢˜å¯ç”¨æ›´ç²— */
      font-size: 2.0rem;
      letter-spacing: -0.5px;
      color: #222222;
      margin-bottom: 18px;
      display: inline-flex;       /* å›¾ç‰‡å’Œæ–‡å­—åœ¨åŒä¸€è¡Œ */
      align-items: center;        /* å‚ç›´å±…ä¸­ */
      justify-content: center;    /* ä¿æŒæ•´ä½“å±…ä¸­ */
      gap: 10px;                  /* å›¾ç‰‡å’Œæ–‡å­—ä¹‹é—´çš„é—´è· */
      text-align: center;          /* æ–‡æœ¬å±…ä¸­ï¼ˆå¯é€‰ï¼‰ */
      margin-left: 180px;
    }
    .title-logo {
      width: 50px;   /* è°ƒæ•´å¤§å° */
      height: 50px;
    }
    .publication-title {
      max-width: 1000px;
      width: 100%;
      margin: 0 auto;        /* ä¿æŒå±…ä¸­åŸºç¡€ */
      margin-left: 200px;     /* å‘å·¦åç§» 20px */
      text-align: justify;
    }
    .content.has-text-justified {
      max-width: 1200px;
      width: 120%;
      margin: 0 auto;        /* ä¿æŒåŸºç¡€å±…ä¸­ */
      position: relative;
      left: -75px;            /* å‘å·¦ç§»åŠ¨ 20px */
      text-align: justify;
    }
    .publication-title .logo-svg {
      margin-right: 4pt;       /* logo ä¸æ–‡å­—é—´è· */
      height: 1.5em;             /* æ ¹æ®æ ‡é¢˜å¤§å°è°ƒæ•´ logo é«˜åº¦ */
    }
   .spacevista-title {
      font-family: "Source Serif 4", Georgia, "Times New Roman", serif;
      font-weight: 600;
      font-size: 1.2em;
      display: inline-flex;
      align-items: center;
      margin-left: 1px;
      font-optical-sizing: auto; 
    }
      
    .logo-svg {
        height: 72px;  
        width: auto;  
        margin-right: 5px;  
        vertical-align: middle; 
    }
          
    .normal-title-wrapper {
      display: inline-block;        /* ä¿æŒå†…è”ï¼Œä½†å¯ä»¥è®¾ç½®å®½åº¦ */
      width: 600px;                 /* çˆ¶å®¹å™¨å®½åº¦ï¼Œæ¯”æ–‡å­—æœ¬èº«å¤§ */
      position: relative;           /* å…è®¸åç§» */
      left: -80px;                  /* å‘å·¦ç§»åŠ¨ 50pxï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ */
      text-align: center;           /* æ–‡å­—åœ¨å®¹å™¨å†…å±…ä¸­ */
    }
    .normal-title {
      white-space: nowrap;          /* é˜²æ­¢æ–‡å­—æ¢è¡Œ */
      font-size: 0.7em !important;
    }
    .unit-mmkm {
      font-weight: bold;
      font-family: 'JetBrains Mono', monospace;
      font-size: 1.0em;
    }

    
    .email-symbol {
      position: absolute;
      top: -5px;
      right: -30px;
      font-size: 14px;
    }

  </style>
</head>
<body>


<!-- æ‚¬æµ®æŒ‰é’® -->
<button id="backToTop" class="back-to-top">â†‘</button>

<style>
  .back-to-top {
    position: fixed;
    top: 50%;                 /* å‚ç›´å±…ä¸­ */
    right: 20px;              /* é å³è¾¹ */
    transform: translateY(-50%); /* ç²¾å‡†å‚ç›´å±…ä¸­ */
    
    width: 40px;
    height: 40px;
    font-size: 18px;
    line-height: 40px;
    text-align: center;
    
    background: #007bff;
    color: #fff;
    border: none;
    border-radius: 50%;       /* åœ†å½¢æŒ‰é’® */
    cursor: pointer;
    z-index: 999;             /* ç¡®ä¿åœ¨æœ€ä¸Šå±‚ */
    box-shadow: 0 2px 6px rgba(0,0,0,0.2);
    transition: background 0.3s;
  }
  .back-to-top:hover {
    background: #0056b3;
  }
</style>

<script>
  document.getElementById("backToTop").addEventListener("click", () => {
    window.scrollTo({
      top: 0,
      behavior: "smooth"   // å¹³æ»‘æ»šåŠ¨åˆ°é¡¶éƒ¨
    });
  });
</script>
  

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img src="./static/images/logo_v2.png" alt="Logo" class="logo-svg">
            <span class="spacevista-title">SpaceVista</span><br>
            <span class="normal-title-wrapper">
              <span class="normal-title">
                All-Scale Visual Spatial Reasoning from 
                <span class="unit-mmkm">mm</span> to 
                <span class="unit-mmkm">km</span>
              </span>
            </span>
            </span>
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Peiwen Sun</a>
              <sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a>Shiqiang Lang</a>
              <sup style="color:#ffac33">3</sup>,
            </span>
            <span class="author-block">
              <a>Dongming Wu</a>
              <sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a>Yi Ding</a>
              <sup style="color:#ed4b82">2</sup>,
            </span>
            <span class="author-block">
              <a>Kaituo Feng</a>
              <sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a>Huadai Liu</a>
              <sup style="color:#9b59b6;">4</sup>,
            </span>
            <span class="author-block">
              <a>Zhen Ye</a>
              <sup style="color:#9b59b6;">4</sup>,
            </span>
            <span class="author-block">
              <a>Rui Liu</a>
              <sup style="color:#6fbf73;">1</sup>,
            </span><br>
            <span class="author-block">
              <a>Yun-Hui Liu</a>
              <sup style="color:#6fbf73;">1</sup>,
            </span>
            <span class="author-block">
              <a>Jianan Wang</a>
              <sup style="color:#ed4b82">2</sup>,
            </span>
            <span class="author-block">
              <a>Xiangyu Yue</a>
              <sup style="color:#6fbf73;">1,</sup>
              <i class="fas fa-envelope email-symbol" style="position: relative; top: -8px; left: 1px;"></i>
            </span>
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>Multimedia Lab, Chinese University of Hong Kong,</span>
            <span class="author-block"><sup style="color:#ed4b82">2</sup>Astribot,</span><br>
            <span class="author-block"><sup style="color:#ffac33">3</sup>Beijing University of Posts and Telecommunications,</span><br>
            <span class="author-block"><sup style="color:#9b59b6;">4</sup>Hong Kong University of Science and Technology</span>
          </div>

          <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-images"></i>
                    </span>
                    <span>Data</span>
                    </a>
              </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="avqa-title">Abstract</h2>
        <img src="./static/images/teaser.jpg" alt="" style="display:block;width:100%;height:auto;margin-bottom:24px;" loading="eager" fetchpriority="high" decoding="async" />
        <div class="content has-text-justified">
        With the current surge in spatial reasoning explorations, researchers have 
        made significant progress in understanding indoor scenes, but still struggle with diverse applications such as robotics and autonomous driving. 
        This paper aims to advance all-scale spatial reasoning across diverse scenarios by tackling two key challenges:
        1) the heavy reliance on indoor 3D scans and labor-intensive manual annotations for dataset curation; 
        2) the absence of effective all-scale scene modeling, which often leads to overfitting to individual scenes.
        In this paper, we introduce a holistic solution that integrates a structured spatial reasoning knowledge system, scale-aware modeling, 
        and a progressive training paradigm, as the <strong>first attempt</strong> to broaden the all-scale spatial intelligence of MLLMs to the best of our knowledge.
        Using a task-specific, specialist-driven automated pipeline, we curate over 38K video scenes across 5 spatial scales to create <strong>SpaceVista-1M</strong>, 
        a dataset comprising approximately 1M spatial QA pairs spanning 19 diverse task types. While specialist models can inject useful domain knowledge, 
        they are not reliable for evaluation. We then build an all-scale benchmark with precise annotations by manually recording, retrieving, and assembling 
        video-based data. However, naive training with SpaceVista-1M often yields suboptimal results due to the potential knowledge conflict. Accordingly, we 
        introduce <strong>SpaceVista-7B</strong>, a spatial reasoning model that accepts dense inputs beyond semantics and uses scale as an anchor for scale-aware experts 
        and progressive rewards. Finally, extensive evaluations across 5 benchmarks, including our <strong>SpaceVista-Bench</strong>, demonstrate competitive 
        performance, showcasing strong generalization across all scales and scenarios.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<div class="fancy-line"></div>
  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="avqa-title2">
          <img src="./static/images/question-logo.png" alt="logo" class="title-logo">
          What is SpaceVista?
        </h2>

        <!-- å¡ç‰‡å®¹å™¨ï¼šåœ†è§’çŸ©å½¢ -->
        <div class="spacevista-card">
          <img src="./static/images/intro_teaser_v3.jpg"
           alt="data_graph"
           class="spacevista-image"
           loading="lazy" decoding="async">

          <!-- å³ä¾§ï¼šæ–‡å­— -->
          <div class="spacevista-card__content content">
            <p>
              Spatial reasoning is the ability to perceive, interpret, and act across spatial scales, from millimeter-sized components to distant aerial scenes. 
              All-scale spatial reasoning is fundamental to next-generation intelligent systems and supports diverse applications: <span class="unit-mmkm">mm</span> sensing for advanced manufacturing,
              <span class="unit-mmkm">cm</span> and <span class="unit-mmkm">m</span> perception for embodied agents, <span class="unit-mmkm">10m</span> operation for autonomous driving, 
              and <span class="unit-mmkm">100m</span> for drone based sensing.<br>
              Despite progress, existing work shows clear limitations in both model design and dataset coverage. Current scene perception research mostly targets indoor scenes, 
              narrow object classes, and limited spatial ranges, and lacks training paradigms engineered for end to end, cross scale reasoning. <strong><span style="color: rgb(0,0,250);">SpaceVista addresses 
              this gap by presenting the first systematic optimization across both data and model dimensions to enable robust, full scene spatial reasoning</span></strong>.
            </p>
          </div>
        </div>
        <!-- /å¡ç‰‡å®¹å™¨ -->

      </div>
    </div>
  </div>
</section>
  
<style>
/* å¡ç‰‡æ•´ä½“ï¼Œå¯è‡ªå®šä¹‰é«˜å®½ */
.spacevista-card {
  display: flex;
  gap: 28px;
  align-items: stretch;          /* å·¦å³ç­‰é«˜ */
  border: 1px solid rgba(0,0,0,0.08);
  border-radius: 16px;
  padding: 28px;
  background: linear-gradient(180deg, #ffffff 0%, #fbfbfd 100%);
  box-shadow: 0 8px 28px rgba(15, 23, 42, 0.06);

  /* è‡ªå®šä¹‰é«˜å®½ */
  width: 120%;
  max-width: 1800px;
  height: 480px;                
  transform: translateX(-8%);
  margin: 0 auto;
  box-sizing: border-box;
}

/* å·¦ä¾§å›¾ç‰‡ */
.spacevista-image {
  flex: 0 0 auto;
  width: auto;
  height: 100%;                 /* ä¸å³ä¾§æ–‡æœ¬ç­‰é«˜ */
  object-fit: contain;           /* å®Œæ•´æ˜¾ç¤ºï¼Œä¸è£åˆ‡ */
  border-radius: 14px;
  box-shadow: 0 6px 20px rgba(15,23,42,0.08);
}

/* å³ä¾§æ–‡å­— */
.spacevista-card__content {
  flex: 1;                      /* å æ»¡å‰©ä½™ç©ºé—´ */
  display: flex;
  align-items: center;           /* å‚ç›´å±…ä¸­ */
  justify-content: flex-start;   /* å·¦å¯¹é½ */
  text-align: justify;
  color: #222;
  line-height: 1.65;
  font-size: 1rem;
}
.spacevista-card__content p {
  margin: 0;
}

/* å°å±å¹•å“åº”å¼ */
@media (max-width: 880px) {
  .spacevista-card {
    flex-direction: column;
    height: auto;
    padding: 16px;
  }
  .spacevista-image {
    width: 100%;
    height: auto;
    max-height: 360px;
    margin-bottom: 12px;
  }
}

</style>


<div class="fancy-line"></div>

<style>
/* è‡ªå®šä¹‰å›¾åƒé£æ ¼ */
.custom-image2 {
  width: 1000px;            /* å®¹å™¨å®½åº¦ï¼Œå¯æ”¹å¤§æˆ–å° */
  max-width: 95vw;           /* é¿å…è¶…å‡ºå±å¹• */
  margin: 0 auto 20px auto;  /* å±…ä¸­ + ä¸‹é—´è· */
  overflow: hidden;          /* é˜²æ­¢å›¾åƒæº¢å‡ºå®¹å™¨ */
  border-radius: 16px;       /* åœ†è§’å¯é€‰ */
  box-shadow: 0 8px 20px rgba(0,0,0,0.1); /* é˜´å½±æ•ˆæœå¯é€‰ */
  transform: translateX(-8%); 
}

.custom-image img {
  width: 100%;               /* å¡«å……å®¹å™¨ */
  height: auto;              /* ä¿æŒçºµæ¨ªæ¯” */
  display: block;
  transition: transform 0.3s ease; /* å¯åŠ ç¼©æ”¾åŠ¨ç”» */
}
  
</style>

  
  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="avqa-title">
          <img src="./static/images/data-logo.png" alt="logo" class="title-logo">
          From <span class="unit-mmkm">mm</span> to <span class="unit-mmkm">km</span> Dataset: SpaceVista-1M
        </h2>
        <div class="content has-text-justified">
          <figure class="custom-image2">
            <img src="./static/images/data_construction_v2.jpg" alt="pipeline">
          </figure>
          In constructing SpaceVista-1M dataset, we first preprocess videos and their associated information, then apply coordinate transformations and task-specific workflows for spatial reasoning. 
          For chain-of-thought annotations, fixed questions (e.g., counting, object size) are generated via over 3,000 curated templates, while flexible questions (e.g., planning) are generated using GPT-based method, 
          with randomized options provided for RL.
        </div>
        <figure class="image">
          <img src="./static/images/data_graph_v2.jpg" alt="data_graph" style="width:600px; height:600px; object-fit:contain; display:block; margin:15px auto 20px auto;" loading="lazy" decoding="async">
        </figure>
        <style>
         .three-columns {
            display: flex;
            justify-content: flex-start;
            align-items: flex-start;
            gap: 40px;
            margin: 40px auto;
            padding: 20px 40px;
            background-color: #f7f7f7;
            border-radius: 8px;
          
            width: 150%;              /* æ¯”é¡µé¢å®½ 120% */
            margin-left: -25%;        /* å‘å·¦ç§»åŠ¨ï¼Œä¿è¯å·¦å³å¯¹ç§° */
            box-sizing: border-box;
          }
          
          .three-columns .column {
            flex: 1;
            min-width: 250px;
          }

          
          /* æ ‡é¢˜æ ·å¼ */
          .three-columns h3 {
            font-family: "Georgia", "Times New Roman", serif; /* æ ‡é¢˜ç”¨è¡¬çº¿å­—ä½“ï¼Œå’Œæ­£æ–‡åŒºåˆ† */
            font-size: 1.5em;   /* æ”¾å¤§å­—å· */
            font-weight: 700;   /* åŠ ç²— */
            color: #1a202c;     /* æ·±è‰² */
            margin-bottom: 10px;
            text-align: left;
          }
          
          /* æ­£æ–‡æ ·å¼ */
          .three-columns p,
          .three-columns li {
            font-family: "Arial", "Helvetica Neue", sans-serif; /* æ­£æ–‡ç”¨æ— è¡¬çº¿å­—ä½“ */
            font-size: 1em;
            line-height: 1.6;
            text-align: left;
            color: #4a5568;
          }
          
          /* åˆ—è¡¨å°åœ†ç‚¹ */
          .middle-column ul {
            list-style: none;
            padding-left: 0;
            margin: 0;
          }
          .middle-column li {
            position: relative;
            padding-left: 18px;
            margin-bottom: 10px;
          }
          .middle-column li::before {
            content: "â€¢";
            position: absolute;
            left: 0;
            top: 0;
            color: #2d3748;       /* æ·±ç°è‰² */
            font-size: 1.1em;
            line-height: 1.2;
            font-weight: bold;    /* ç²—ä¸€ç‚¹ */
          }

        </style>
        
        <div class="three-columns">
          <div class="column">
            <h3>Basic informations</h3>
            <p>We collect a large number of spatial reasoning videos from both open-source datasets and our own ollected data. Specifically, we select scenes including tabletop, indoor, 
              outdoor, and drone-view scenes, and design 19 types of spatial reasoning tasks covering all-scale from millimeters to kilometers. The dataset contains diverse spatial 
              reasoning questionâ€“answer pairs, enriched with semantic, 2D, and 3D annotations.</p>
          </div>
        
          <div class="column middle-column">
            <h3>Characteristics</h3>
            <ul>
              <li>5 spatial scales scenes</li>
              <li>19 spatial reasoning task type</li>
              <li>All-scale: from mm to km</li>
              <li>3,8000 videos across diverse scenes</li>
              <li>Over 50 subscene categories</li>
              <li>1 million QA pairs</li>
              <li>Video Data with 3D Modeling</li>
              <li>Comprehensive Annotations & Metadata</li>
            </ul>
          </div>
        
          <div class="column">
            <h3>Our own collected data</h3>
            <p>Although we perform limited manual filtering on open-source data, its suitability for accurately evaluating real-world perception remains uncertain. 
              To address this, we collect higher-fidelity data comprising two types: <br>
              <ul>
                <li>1) measured, recorded, and manually annotated data for tiny and tabletop objects</li>
                <li>2) existing videos enhanced through retrieval and verification of public information for indoor and outdoor scenes.</li>
              </ul>
          </div>
        </div>

        </div>
        </div>
      </div>
    </div>
  </div>
</section>  


<div class="fancy-line"></div>  

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="avqa-title">
          <img src="./static/images/model-logo.png" alt="logo" class="title-logo">
          Model: SpaceVista-7B
        </h2>
        <div class="content has-text-justified">
          <figure class="custom-image">
            <img src="./static/images/pipeline_v4.jpg" alt="pipeline">
          </figure>
          SpaceVista-7B ingests a question with images and videos and 3D geometry, encodes them, projects features to a shared space, and fuses them in an 
          LLM through learnable interaction. A LoRA-like scale expert with a scale aware router adapts the model to different spatial scales. 
          Training uses reinforcement learning with stepwise rewards, including scale estimation, semantic recognition, result correctness, and format correctness, 
          to align reasoning and final answers.
        </div>
      </div>
    </div>
  </div>
</section> 

<style>
/* è‡ªå®šä¹‰å›¾åƒé£æ ¼ */
.custom-image {
  width: 1000px;            /* å®¹å™¨å®½åº¦ï¼Œå¯æ”¹å¤§æˆ–å° */
  max-width: 95vw;           /* é¿å…è¶…å‡ºå±å¹• */
  margin: 0 auto 20px auto;  /* å±…ä¸­ + ä¸‹é—´è· */
  overflow: hidden;          /* é˜²æ­¢å›¾åƒæº¢å‡ºå®¹å™¨ */
  border-radius: 16px;       /* åœ†è§’å¯é€‰ */
  box-shadow: 0 8px 20px rgba(0,0,0,0.1); /* é˜´å½±æ•ˆæœå¯é€‰ */
  transform: translateX(-8%); 
}

.custom-image img {
  width: 100%;               /* å¡«å……å®¹å™¨ */
  height: auto;              /* ä¿æŒçºµæ¨ªæ¯” */
  display: block;
  transition: transform 0.3s ease; /* å¯åŠ ç¼©æ”¾åŠ¨ç”» */
}
  
</style>

  
<div class="fancy-line"></div>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="avqa-title">
          <img src="./static/images/expriment-logo.png" alt="logo" class="title-logo">
          Experiment
        </h2>
        <style>
          .img-text-row {
            display: flex;
            align-items: flex-start;   /* å·¦å›¾é¡¶éƒ¨ä¸å³æ–‡æœ¬é¡¶éƒ¨å¯¹é½ */
            gap: 40px;                 /* å·¦å³é—´è· */
            margin: 40px auto;
            width: 160%;               /* è¶…å‡ºçˆ¶å®¹å™¨å®½åº¦ */
            max-width: none;           /* å–æ¶ˆæœ€å¤§å®½åº¦é™åˆ¶ */
            transform: translateX(-20%); /* å‘å·¦åç§»ï¼Œä½¿è§†è§‰å±…ä¸­ */
            box-sizing: border-box;
          }
        
          .img-text-row .image-container img {
            display: block;
            width: 2000px;              /* å›¾ç‰‡æ”¾å¤§ */
            height: auto;              /* ç­‰æ¯”ä¾‹ç¼©æ”¾ */
            object-fit: contain;
          }
        
          .img-text-row .text-container {
            display: flex;
            flex-direction: column;    /* ä¸Šä¸‹æ’åˆ—æ–‡æœ¬ */
            justify-content: flex-start; /* é¡¶éƒ¨å¯¹é½ */
            gap: 20px;                 /* æ–‡æœ¬æ®µè½é—´è· */
            max-width: 700px;          /* æ–‡æœ¬æœ€å¤§å®½åº¦ï¼Œå¯è‡ªè¡Œè°ƒæ•´ */
          }
        
          .img-text-row .text-container p {
            text-align: justify;
            line-height: 1.6;
            color: #4a5568;
          }
        
          .img-text-row .text-container strong {
            color: #1a202c;
          }
        </style>
        
        <div class="img-text-row">
          <div class="image-container">
            <img src="./static/images/radar.png" alt="experiment-2" loading="lazy" decoding="async">
          </div>
        
          <div class="text-container">
            <p>
              <strong>Results overview.</strong> SpaceVista-7B achieve significant improvements across all benchmarks, highlighting its advantages in spatial reasoning tasks. 
              Although models including LLAVA-Onevision-7B also demonstrate competitive performance, SpaceVista-7B consistently shows greater robustness and adaptability across various tasks, 
              thereby solidifying its position as a leading model in the field of spatial reasoning.
            </p>
            <p>
              <strong>Evaluation suite.</strong> The comparison across models is conducted on multiple spatial reasoning benchmarks. We conduct a comprehensive evaluation of LLAVA-Onevision-7B, 
              LLAVA-Next-Video-7B, InternVL3.5-8B, Qwen2.5-VL-7B, SpaceR-7B, SpatialMLLM-4-B, VILASR-7B, and our SpaceVista-7B on VSI-Bench, STI-Bench, MMSI-Bench, SPAR-Bench, and SpaceVista-Bench, 
              highlighting the robustness and competitiveness of our model.
            </p>
          </div>
        </div>
      </div>
      </div>
    </div>
  </div>
</section>


<style>
  .table-note {
    text-align: center;   /* æ–‡æœ¬æ°´å¹³å±…ä¸­ */
    margin: 0 auto 25px;       /* å®¹å™¨æœ¬èº«å±…ä¸­ */
    max-width: 800px;     /* å¯é€‰ï¼šé™åˆ¶å®½åº¦æ›´ç¾è§‚ */
  }  
</style>
  
<div id="mv-lb">
  <div class="mv-head">
    <h2 class="avqa-title">
      <img src="./static/images/leaderboard-logo.png" alt="logo" class="title-logo">
      Leaderboard on SpaceVista-Bench
    </h2>
  </div>
  <div class="table-note">
    Click the table header to sort in ascending or descending order.<br>
    <span class="top-model"><a class="mv-top"><strong>Models highlighted in bold red</strong></a></span> indicate the top three overall performers on SpaceVista-Bench.
  </div>
  <div class="mv-table-wrap">
    <table id="mv-lb-table" class="mv-table" aria-label="Leaderboard on SpaceVista (test)">
      <thead>
        <tr>
          <th class="center w-idx" data-type="number" aria-sort="none"># <span class="mv-ind"></span></th>
          <th class="w-model" data-type="string" aria-sort="none">Model <span class="mv-ind"></span></th>
          <th data-type="string" aria-sort="none">Source <span class="mv-ind"></span></th>
          <th data-type="date" aria-sort="none">Date <span class="mv-ind"></span></th>
          <th class="num col-all" data-type="number" aria-sort="none">Overall <span class="mv-ind"></span></th>
          <th class="num" data-type="number" aria-sort="none">Tiny Tabletop <span class="mv-ind"></span></th>
          <th class="num" data-type="number" aria-sort="none">Tabletop <span class="mv-ind"></span></th>
          <th class="num" data-type="number" aria-sort="none">Indoor <span class="mv-ind"></span></th>
          <th class="num" data-type="number" aria-sort="none">Outdoor <span class="mv-ind"></span></th>
        </tr>
      </thead>
      <tbody>
       <tr> <td class="center">3</td> <td><a class="mv-top"><strong>GPT-5</strong> ğŸ¥‰</a></td> <td><a href="https://openai.com/gpt-5/">Link</a></td> <td>2025-08</td> <td class="num col-all">33.7</td><td class="num">32.2</td><td class="num">20.3</td><td class="num">39.0</td><td class="num">43.0</td></tr> 
       <tr> <td class="center">8</td> <td>GPT-4o </a></td> <td><a href="https://gpt4o.ai/">Link</a></td> <td>2024-05</td> <td class="num col-all">26.9</td><td class="num">21.7</td><td class="num">13.3</td><td class="num">34.3</td><td class="num">38.3</td></tr> 
        <tr> <td class="center">2</td> <td><a class="mv-top"><strong>Gemini-2.5-Pro</strong> ğŸ¥ˆ</a></td> <td><a href="https://deepmind.google/technologies/gemini/pro/">Link</a></td> <td>2025-06</td> <td class="num col-all">33.8</td><td class="num">33.0</td><td class="num">38.7</td><td class="num">34.5</td><td class="num">29.0</td></tr> 
        <tr> <td class="center">11</td> <td>Gemini-2.5-Flash</td> <td><a href="https://deepmind.google/models/gemini/flash/">Link</a></td> <td>2025-06</td> <td class="num col-all">24.4</td><td class="num">20.7</td><td class="num">30.0</td><td class="num">19.9</td><td class="num">26.9</td></tr> 
        <tr> <td class="center">6</td> <td>Claude-Sonnet-4</td> <td><a href="https://www.anthropic.com/claude/sonnet">Link</a></td> <td>2025-05</td> <td class="num col-all">29.7</td><td class="num">27.3</td><td class="num">19.3</td><td class="num">38.1</td><td class="num">34.1</td></tr> 
        <tr> <td class="center">10</td> <td>Claude-Opus-4.1</td> <td><a href="https://www.anthropic.com/news/claude-opus-4-1">Link</a></td> <td>2025-08</td> <td class="num col-all">26.4</td><td class="num">21.7</td><td class="num">29.5</td><td class="num">24.3</td><td class="num">30.0</td></tr> 
        <tr> <td class="center">5</td> <td>Internvl3.5-38B</td> <td><a href="https://huggingface.co/OpenGVLab/InternVL3_5-38B-Instruct">Link</a></td> <td>2025-08</td> <td class="num col-all">30.7</td><td class="num">29.3</td><td class="num">25.2</td><td class="num">41.2</td><td class="num">27.0</td></tr> 
        <tr> <td class="center">10</td> <td>Internvl3.5-14B</td> <td><a href="https://huggingface.co/OpenGVLab/InternVL3_5-14B-Instruct">Link</a></td> <td>2025-08</td> <td class="num col-all">26.4</td><td class="num">27.7</td><td class="num">22.3</td><td class="num">31.3</td><td class="num">24.3</td></tr> 
        <tr> <td class="center">4</td> <td>Internvl3-78B</td> <td><a href="https://huggingface.co/OpenGVLab/InternVL3-78B">Link</a></td> <td>2025-04</td> <td class="num col-all">33.5</td><td class="num">38.3</td><td class="num">23.3</td><td class="num">42.2</td><td class="num">30.3</td></tr> 
        <tr> <td class="center">9</td> <td>Internvl3-38B</td> <td><a href="https://huggingface.co/OpenGVLab/InternVL3-38B">Link</a></td> <td>2025-04</td> <td class="num col-all">26.5</td><td class="num">18.7</td><td class="num">14.3</td><td class="num">34.8</td><td class="num">38.0</td></tr> 
        <tr> <td class="center">13</td> <td>GLM-4.5V</td> <td><a href="https://www.glm45.com/glm45v">Link</a></td> <td>2025-08</td> <td class="num col-all">23.3</td><td class="num">23.0</td><td class="num">17.8</td><td class="num">27.3</td><td class="num">25.2</td></tr>
        <tr> <td class="center">14</td> <td>GLM-4.1V-Thinking</td> <td><a href="https://huggingface.co/zai-org/GLM-4.1V-9B-Thinking">Link</a></td> <td>2025-07</td> <td class="num col-all">23.1</td><td class="num">30.7</td><td class="num">19.3</td><td class="num">29.0</td><td class="num">13.3</td></tr>
        <tr> <td class="center">10</td> <td>Qwen2.5VL-72B</td> <td><a href="https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct">Link</a></td> <td>2025-01</td> <td class="num col-all">26.4</td><td class="num">27.7</td><td class="num">20.3</td><td class="num">29.6</td><td class="num">28.0</td></tr>
        <tr> <td class="center">7</td> <td>Qwen2.5VL-32B</td> <td><a href="https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct">Link</a></td> <td>2025-01</td> <td class="num col-all">28.4</td><td class="num">25.3</td><td class="num">19.3</td><td class="num">38.1</td><td class="num">30.7</td></tr>
        <tr> <td class="center">16</td> <td>LLAVA-Onevision-72B</td> <td><a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-72b-ov-hf">Link</a></td> <td>2024-08</td> <td class="num col-all">16.0</td><td class="num">25.0</td><td class="num">12.0</td><td class="num">15.3</td><td class="num">11.7</td></tr>
        <tr> <td class="center">17</td> <td>LLAVA-Onevision-7B</td> <td><a href="https://huggingface.co/lmms-lab/llava-onevision-qwen2-7b-ov">Link</a></td> <td>2024-08</td> <td class="num col-all">12.6</td><td class="num">17.5</td><td class="num">8.0</td><td class="num">13.3</td><td class="num">11.6</td></tr>
        <tr> <td class="center">15</td> <td>SpaceR</td> <td><a href="https://github.com/OuyangKun10/SpaceR">Link</a></td> <td>2025-04</td> <td class="num col-all">21.2</td><td class="num">12.9</td><td class="num">17.3</td><td class="num">34.9</td><td class="num">19.8</td></tr>
        <tr> <td class="center">12</td> <td>Spatial-MLLM</td> <td><a href="https://github.com/diankun-wu/Spatial-MLLM?tab=readme-ov-file">Link</a></td> <td>2025-05</td> <td class="num col-all">24.2</td><td class="num">17.3</td><td class="num">20.3</td><td class="num">36.1</td><td class="num">23.1</td></tr>
        <tr> <td class="center">1</td> <td><a class="mv-top"><strong>SpaceVista-7B</strong> ğŸ¥‡</td> <td><a href="">Link</a></td> <td>2025-09</td> <td class="num col-all">36.7</td><td class="num">33.4</td><td class="num">37.1</td><td class="num">42.2</td><td class="num">34.1</td></tr>
      </tbody>
    </table>
  </div>
</div>

<style>
  .mv-top {
    color: #B22222; /* DarkRed */
  }
  /* ä»…ä½œç”¨äº #mv-lb ä½œç”¨åŸŸï¼Œé¿å…å½±å“é¡µé¢å…¶å®ƒéƒ¨åˆ† */
  #mv-lb {
    --mv-max: 1200px;          /* å¯è‡ªå®šä¹‰å®¹å™¨æœ€å¤§å®½åº¦ */
    max-width: var(--mv-max);
    width: 100%;
    margin: 0 auto;            /* å®¹å™¨æ°´å¹³å±…ä¸­ */
  }
  #mv-lb{--mv-text:#333;--mv-muted:#666;--mv-head-bg:#e9ecef;--mv-border:#d9d9d9;--mv-row-alt:#fafafa;--mv-accent:#c70000;}
  #mv-lb .mv-head{ text-align:center; margin:0 0 12px; }  /* æ ‡é¢˜åŒºå±…ä¸­ */
  #mv-lb .mv-head h2{ margin:10px 0 6px; font-size:32px; color:var(--mv-text); font-weight:700; }
  #mv-lb .mv-head p{ margin:0; color:var(--mv-muted); font-size:14px; }

  #mv-lb .mv-table-wrap{ overflow-x:auto; -webkit-overflow-scrolling:touch; }
  #mv-lb .mv-table{ width:100%; border-collapse:separate; border-spacing:0; border:1px solid var(--mv-border); }
  #mv-lb .mv-table thead th{
    background:var(--mv-head-bg); color:#222; padding:10px 12px;
    border-bottom:1px solid var(--mv-border); font-weight:700; white-space:nowrap; user-select:none; cursor:pointer;
  }
  #mv-lb .mv-table tbody td{ padding:10px 12px; border-bottom:1px solid var(--mv-border); color:var(--mv-text); }
  #mv-lb .mv-table tbody tr:nth-child(even){ background:var(--mv-row-alt); }

  /* å¯é€‰åˆ—å®½è®¾å®š */
  #mv-lb .w-idx{ width:36px; }
  #mv-lb .w-model{ min-width:220px; }

  /* ====== è¦†ç›–å¯¹é½ï¼ˆæ”¾åœ¨æœ€åï¼Œç¡®ä¿å…¨éƒ¨å±…ä¸­ï¼‰====== */
  #mv-lb .mv-table th,
  #mv-lb .mv-table td{
    text-align:center;     /* æ°´å¹³å±…ä¸­ */
    vertical-align:middle; /* å‚ç›´å±…ä¸­ */
  }
  /* æ•°å­—åˆ—ä¹Ÿå±…ä¸­ï¼ˆè¦†ç›–åŸæ¥çš„å³å¯¹é½ï¼‰ */
  #mv-lb .mv-table .num{ text-align:center; }
  /* æœ‰äº›å•å…ƒæ ¼å¸¦ .center ç±»ï¼Œç»Ÿä¸€ä¿æŒå±…ä¸­ */
  #mv-lb .center{ text-align:center; }
</style>

<script>
(function(){
  const table = document.getElementById('mv-lb-table');
  if(!table) return;
  const tbody = table.tBodies[0];
  const headers = table.tHead.rows[0].cells;

  [...headers].forEach((th, idx) => {
    th.tabIndex = 0;
    const handler = (e) => {
      if (e.type==='click' || e.key==='Enter' || e.key===' ') { e.preventDefault?.(); sortBy(idx, th); }
    };
    th.addEventListener('click', handler);
    th.addEventListener('keydown', handler);
  });

  function parseCell(td, type){
    const t = td.textContent.trim();
    if (type==='number'){
      const n = parseFloat(t.replace(/[^\d.+-]/g,''));
      return Number.isNaN(n) ? -Infinity : n;
    }
    if (type==='date'){
      const d = Date.parse(t);
      return Number.isNaN(d) ? -Infinity : d;
    }
    return t.toLowerCase();
  }

  function resetIndicators(except){
    [...headers].forEach(h=>{
      if(h!==except){
        h.dataset.direction = '';
        h.setAttribute('aria-sort','none');
        const i = h.querySelector('.mv-ind'); if(i) i.textContent = '';
      }
    });
  }

  function sortBy(col, th){
    const type = th.dataset.type || 'string';
    const next = (th.dataset.direction==='desc') ? 'asc' : 'desc'; // å…ˆé™åº
    th.dataset.direction = next;
    th.setAttribute('aria-sort', next==='desc' ? 'descending' : 'ascending');
    resetIndicators(th);
    const ind = th.querySelector('.mv-ind'); if(ind) ind.textContent = next==='desc' ? 'â–¼' : 'â–²';

    const rows = Array.from(tbody.rows).map((row, i)=>({ row, key: parseCell(row.cells[col], type), idx:i }));
    const mul = next==='desc' ? -1 : 1;
    rows.sort((a,b)=>{
      if (a.key < b.key) return -1*mul;
      if (a.key > b.key) return  1*mul;
      return a.idx - b.idx;
    });
    const frag = document.createDocumentFragment();
    rows.forEach(r=>frag.appendChild(r.row));
    tbody.appendChild(frag);
  }
})();
</script>

<div class="fancy-line"></div>
  
<style>
    /* Self-Collected æŒ‰é’® tooltip æ ·å¼ */
  .scene-switcher .button.self-collected {
    position: relative;
  }
  
  /* Tooltip æ ·å¼ */
  .scene-switcher .button.self-collected::after {
    content: "We use standard ISO 7046 to denote the models of the screw, which looks like â€œm4*10â€";
    position: absolute;
    bottom: calc(100% + 8px);  /* tooltip åœ¨æŒ‰é’®ä¸Šæ–¹ */
    left: 50%;
    transform: translateX(-50%);
    background: #363636;
    color: #fff;
    font-size: 12px;
    padding: 6px 8px;
    border-radius: 6px;
    white-space: nowrap;
    opacity: 0;
    pointer-events: none;
    transition: opacity 0.2s, transform 0.2s;
    z-index: 10;
  }
  
  /* å°ç®­å¤´ */
  .scene-switcher .button.self-collected::before {
    content: "";
    position: absolute;
    bottom: 100%;
    left: 50%;
    transform: translateX(-50%);
    border: 6px solid transparent;
    border-top-color: #363636;
    opacity: 0;
    transition: opacity 0.2s;
    z-index: 10;
  }
  
  /* æ‚¬åœæ˜¾ç¤º tooltip */
  .scene-switcher .button.self-collected:hover::after,
  .scene-switcher .button.self-collected:hover::before {
    opacity: 1;
    transform: translateX(-50%) translateY(0);
  }
  /* ç»Ÿä¸€å®½åº¦å®¹å™¨ */
  .scene-container {
    width: 960px;
    margin: 0 auto;
  }

  /* æŒ‰é’®åŒº */
  .scene-switcher {
    display: flex;
    width: 100%;
    border-radius: 10px 10px 0 0;
    overflow: visible;
    background: #f0f0f0;
  }

  .scene-switcher .button {
    position: relative;
    flex: 1;
    font-weight: 600;
    border-radius: 0;
    border: none;
    box-shadow: none;
    margin: 0;
    padding: 12px 0;
    font-size: 15px;
    color: #555;
    background: #f0f0f0;
    transition: all 0.25s ease;
    cursor: pointer;
  }

  .scene-switcher .button:hover { background: #e0e0e0; color: #000; }
  .scene-switcher .button.is-active { background: #363636; color: #fff; font-weight: 700; }

  /* å±•ç¤ºåŒº */
  .scene-frame {
    width: 960px;
    height: 680px;
    border: 1.5px solid #bbb;
    border-top: none;
    border-radius: 0 0 10px 10px;
    background: #fafafa;
    display: flex;
    align-items: center;
    justify-content: center;
    overflow: hidden;
  }
  .scene-frame img {
    width: 100%;
    height: 100%;
    object-fit: contain;
  }

  .scene-switcher .button:not(.is-active)::after {
    content: "Click to switch scenes";
    position: absolute;
    left: 50%;
    top: calc(100% + 10px);
    transform: translateX(-50%) translateY(4px);
    background: #363636;
    color: #fff;
    font-size: 8px;
    line-height: 1;
    padding: 6px 8px;
    border-radius: 6px;
    white-space: nowrap;
    pointer-events: none;
    opacity: 0;
    transition: opacity .18s ease, transform .18s ease;
    z-index: 2;
  }
  .scene-switcher .button:not(.is-active)::before {
    content: "";
    position: absolute;
    left: 50%;
    top: 100%;
    transform: translateX(-50%);
    border: 6px solid transparent;
    border-top-color: #363636;
    opacity: 0;
    transition: opacity .18s ease;
    z-index: 2;
  }
  .scene-switcher .button:not(.is-active):hover::after,
  .scene-switcher .button:not(.is-active):hover::before {
    opacity: 1;
    transform: translateX(-50%) translateY(0);
  }
  .scene-row .scene-gallery .scene-switcher .button {
    font-size: 13px;   /* æ”¹æˆä½ éœ€è¦çš„å€¼ï¼Œå¦‚ 12/14/16px */
    line-height: 1.2;  /* å¯é€‰ï¼šè®©æ–‡å­—æ›´ç´§å‡‘ */
    /* å¯é€‰ï¼šè°ƒèŠ‚å†…è¾¹è·ï¼Œé¿å…æŒ‰é’®å˜å¾—è¿‡é«˜æˆ–è¿‡çŸ® */
    padding-top: 10px;
    padding-bottom: 10px;
  }
  /* === æ–°å¢ï¼šå·¦å³å¹¶æ’å¸ƒå±€ï¼ˆä¸æ”¹å˜å…¶å®ƒæ ·å¼çš„è¡Œä¸ºï¼‰ === */
  .scene-row {
    width: 1200px;              /* å¦‚éœ€å…¨å®½å¯æ”¹ä¸º 100% */
    max-width: 100%;
    margin: 0 auto;
    display: flex;
    gap: 24px;                  /* ä¸¤ä¸ªå®¹å™¨ä¹‹é—´çš„é—´è· */
    align-items: flex-start;
    justify-content: center;
  }
  /* ä»…å½“ä½œä¸º .scene-row å­å…ƒç´ æ—¶è¦†ç›–å›ºå®šå®½åº¦ä¸å¤–è¾¹è· */
  .scene-row .scene-container {
    margin: 0;                  /* è¦†ç›–åŸæœ¬çš„å±…ä¸­å¤–è¾¹è· */
    flex: 1 1 0;                /* ç­‰åˆ†å®½åº¦ */
    width: auto;                /* è¦†ç›–åŸæ¥çš„ width:960px */
  }
  .scene-row .scene-switcher { width: 100%; }
  .scene-row .scene-frame {
    width: 100%;                /* è¦†ç›–åŸæ¥çš„ width:960px */
    height: 420px;              /* è°ƒæ•´ä¸ºæ›´é€‚åˆå¹¶æ’æ˜¾ç¤ºçš„é«˜åº¦ */
  }
  
  @media (max-width: 1100px) {
    .scene-row { flex-direction: column; }
    .scene-row .scene-frame { height: 480px; }
  }
  .scene-row .scene-gallery .title.is-3{
      font-size: 24px;  
      line-height: 1.25;
  }
  
</style>

  
<section class="section">
  <div class="is-centered has-text-centered">

    <!-- ä¸€è¡Œå®¹å™¨ï¼Œå·¦å³å¹¶æ’æ”¾ç½®ä¸¤ä¸ªç»„ä»¶ -->
    <div class="scene-row">

      <!-- ===== ç»„ä»¶å®ä¾‹ A ===== -->
      <div class="scene-container scene-gallery">
        <div class="avqa-title">Scenes Data Preview</div>

        <div class="scene-switcher">
          <button type="button" class="button" data-src="./static/images/D6_uco_3d_data.jpg">Tiny Tabletop</button>
          <button type="button" class="button" data-src="./static/images/D5_wildrgbd_data.jpg">Tabletop</button>
          <button type="button" class="button" data-src="./static/images/D7_our_collected.jpg">Self-Collected</button>
          <button type="button" class="button is-active" data-src="./static/images/D1_vsi_data.jpg">Indoor</button>
          <button type="button" class="button" data-src="./static/images/D2_DL3DV_indoor_data.jpg">Wild Indoor</button>
          <button type="button" class="button" data-src="./static/images/D3_DL3DV_outdoor_data.jpg">Outdoor</button>
          <button type="button" class="button" data-src="./static/images/D4_DL3DV_drone_data.jpg">Drone</button>
        </div>

        <div class="scene-frame">
          <img data-role="scene" src="" alt="Scene A" loading="eager" fetchpriority="high" decoding="async">
        </div>
      </div>

      <!-- ===== ç»„ä»¶å®ä¾‹ B ===== -->
      <div class="scene-container scene-gallery">
        <div class="avqa-title">Word Cloud</div>

        <div class="scene-switcher">
          <button type="button" class="button is-active" data-src="./static/images/tinytabletop_data.jpg">Tiny Tabletop</button>
          <button type="button" class="button" data-src="./static/images/indoor_data.jpg">Tabletop</button>
          <button type="button" class="button" data-src="./static/images/ourcollected_data.jpg">Self-Collected</button>
          <button type="button" class="button" data-src="./static/images/previous_indoor_data.jpg">Previous Indoor</button>
          <button type="button" class="button" data-src="./static/images/indoor_data.jpg">Indoor</button>
          <button type="button" class="button" data-src="./static/images/outdoor_data.jpg">Outdoor</button>
        </div>

        <div class="scene-frame">
          <img data-role="scene" src="" alt="Scene B" loading="eager" decoding="async">
        </div>
      </div>

    </div><!-- /scene-row -->

  </div>
</section>

<script>
(function(){
  function setupGallery(root){
    const img = root.querySelector('img[data-role="scene"]');
    const btns = Array.from(root.querySelectorAll('.scene-switcher .button'));
    if (!img || btns.length === 0) return;

    function setActive(btn, opts={}) {
      const src = btn.dataset.src;
      if (!src) return;

      // æŒ‰é’®æ€
      btns.forEach(b => b.classList.toggle('is-active', b === btn));

      // é¢„è½½å¹¶åˆ‡æ¢ï¼ˆå¸¦æ·¡å…¥ï¼‰
      if (img.getAttribute('src') !== src) {
        img.style.opacity = 0;
        const pre = new Image();
        pre.onload = () => {
          img.src = src;
          img.alt = btn.textContent.trim() || img.alt;
          (img.decode ? img.decode() : Promise.resolve()).catch(()=>{}).finally(()=>{
            img.style.transition = 'opacity .2s ease';
            img.style.opacity = 1;
          });
        };
        pre.src = src;
      } else {
        // åˆå§‹æ—¶åªåŒæ­¥ alt
        img.alt = btn.textContent.trim() || img.alt;
      }

      // é¦–æ¬¡å¯æé«˜ä¼˜å…ˆçº§ï¼Œå…¶ä½™ä¸º auto
      img.setAttribute('fetchpriority', opts.initial ? 'high' : 'auto');
    }

    // äº‹ä»¶ç»‘å®š
    btns.forEach((b, idx) => {
      b.addEventListener('click', () => setActive(b));
      b.addEventListener('mouseenter', () => { // æ‚¬åœé¢„åŠ è½½
        const s = b.dataset.src; if (s) { const i = new Image(); i.src = s; }
      });
      b.addEventListener('keydown', (e) => {
        if (e.key === 'Enter' || e.key === ' ') { e.preventDefault(); setActive(b); }
        if (e.key === 'ArrowLeft' || e.key === 'ArrowRight') {
          e.preventDefault();
          const next = e.key === 'ArrowLeft' ? (idx - 1 + btns.length) % btns.length
                                             : (idx + 1) % btns.length;
          btns[next].focus();
        }
      });
    });

    // åˆå§‹åŒ–ï¼šä¼˜å…ˆä½¿ç”¨å·²æœ‰ .is-activeï¼Œå…¶æ¬¡ç¬¬ä¸€é¡¹
    const initBtn = root.querySelector('.scene-switcher .button.is-active') || btns[0];
    if (initBtn) setActive(initBtn, { initial: true });
  }

  document.querySelectorAll('.scene-gallery').forEach(setupGallery);
})();
  // ç»™ Self-Collected æŒ‰é’®åŠ  class
  document.querySelectorAll('.scene-switcher .button').forEach(btn => {
    if(btn.textContent.trim() === "Self-Collected"){
      btn.classList.add('self-collected');
    }
  });
</script>


  

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> 
            of <a href="https://nerfies.github.io/">Nerfies website</a>, 
            we just ask that you link back to Nerfies page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
